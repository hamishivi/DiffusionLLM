{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: You are reviewing papers for the World\u2019s Fanciest Machine Learning Conference, and you see submissions with the following claims. Which ones would you consider accepting?  (A) My method achieves a training error lower than all previous methods! (B) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise test error.) (C) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) (D) My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) A: C | Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: Which of the following guidelines is applicable to initialization of the weight vector in a fully connected neural network. (A) Should not set it to zero since otherwise it will cause overfitting (B) Should not set it to zero since otherwise (stochastic) gradient descent will explore a very small space (C) Should set it to zero since otherwise it causes a bias (D) Should set it to zero in order to preserve symmetry across all neurons A:", "targets": "B"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: You are reviewing papers for the World\u2019s Fanciest Machine Learning Conference, and you see submissions with the following claims. Which ones would you consider accepting?  (A) My method achieves a training error lower than all previous methods! (B) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise test error.) (C) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) (D) My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) A: C | Q: Which of the following statements about Naive Bayes is incorrect? (A) Attributes are equally important. (B) Attributes are statistically dependent of one another given the class value. (C) Attributes are statistically independent of one another given the class value. (D) Attributes can be nominal or numeric A:", "targets": "B"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: Statement 1| The L2 penalty in a ridge regression is equivalent to a Laplace prior on the weights. Statement 2| There is at least one set of 4 points in R^3 that can be shattered by the hypothesis set of all 2D planes in R^3. (A) True, True (B) False, False (C) True, False (D) False, True A:", "targets": "D"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: You are reviewing papers for the World\u2019s Fanciest Machine Learning Conference, and you see submissions with the following claims. Which ones would you consider accepting?  (A) My method achieves a training error lower than all previous methods! (B) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise test error.) (C) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) (D) My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) A: C | Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: For the one-parameter model, mean-Square error (MSE) is defined as follows: 1/(2N) \\sum (y_n \u2212 \u03b2_0)^2 . We have a half term in the front because, (A) scaling MSE by half makes gradient descent converge faster. (B) presence of half makes it easy to do grid search.  (C) it does not matter whether half is there or not.  (D) none of the above A:", "targets": "C"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: In Yann LeCun's cake, the cherry on top is (A) reinforcement learning (B) self-supervised learning (C) unsupervised learning (D) supervised learning A:", "targets": "A"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: What is the dimensionality of the null space of the following matrix? A = [[1, 1, 1], [1, 1, 1], [1, 1, 1]] (A) 0 (B) 1 (C) 2 (D) 3 A:", "targets": "C"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: The number of test examples needed to get statistically significant results should be _ (A) Larger if the error rate is larger. (B) Larger if the error rate is smaller. (C) Smaller if the error rate is smaller. (D) It does not matter. A:", "targets": "B"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: Compared to the variance of the Maximum Likelihood Estimate (MLE), the variance of the Maximum A Posteriori (MAP) estimate is ________ (A) higher (B) same (C) lower (D) it could be any of the above A:", "targets": "C"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: You are reviewing papers for the World\u2019s Fanciest Machine Learning Conference, and you see submissions with the following claims. Which ones would you consider accepting?  (A) My method achieves a training error lower than all previous methods! (B) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise test error.) (C) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) (D) My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) A: C | Q: Which of the following best describes the joint probability distribution P(X, Y, Z) for the given Bayes net. X <- Y -> Z? (A) P(X, Y, Z) = P(Y) * P(X|Y) * P(Z|Y) (B) P(X, Y, Z) = P(X) * P(Y|X) * P(Z|Y) (C) P(X, Y, Z) = P(Z) * P(X|Z) * P(Y|Z) (D) P(X, Y, Z) = P(X) * P(Y) * P(Z) A:", "targets": "A"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: You are reviewing papers for the World\u2019s Fanciest Machine Learning Conference, and you see submissions with the following claims. Which ones would you consider accepting?  (A) My method achieves a training error lower than all previous methods! (B) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise test error.) (C) My method achieves a test error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) (D) My method achieves a cross-validation error lower than all previous methods! (Footnote: When regularisation parameter \u03bb is chosen so as to minimise cross-validaton error.) A: C | Q: Which image data augmentation is most common for natural images? (A) random crop and horizontal flip (B) random crop and vertical flip (C) posterization (D) dithering A: A | Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: You observe the following while fitting a linear regression to the data: As you increase the amount of training data, the test error decreases and the training error increases. The train error is quite low (almost what you expect it to), while the test error is much higher than the train error. What do you think is the main reason behind this behavior. Choose the most probable option. (A) High variance (B) High model bias (C) High estimation bias (D) None of the above A:", "targets": "A"}
{"inputs": "The following are multiple choice questions (with answers) about machine learning. Q: Traditionally, when we have a real-valued input attribute during decision-tree learning we consider a binary split according to whether the attribute is above or below some threshold. Pat suggests that instead we should just have a multiway split with one branch for each of the distinct values of the attribute. From the list below choose the single biggest problem with Pat\u2019s suggestion: (A) It is too computationally expensive. (B) It would probably result in a decision tree that scores badly on the training set and a testset. (C) It would probably result in a decision tree that scores well on the training set but badly on a testset. (D) It would probably result in a decision tree that scores well on a testset but badly on a training set. A: C | Q: A 6-sided die is rolled 15 times and the results are: side 1 comes up 0 times; side 2: 1 time; side 3: 2 times; side 4: 3 times; side 5: 4 times; side 6: 5 times. Based on these results, what is the probability of side 3 coming up when using Add-1 Smoothing? (A) 2.0/15 (B) 1.0/7 (C) 3.0/16 (D) 1.0/5 A: B | Q: To achieve an 0/1 loss estimate that is less than 1 percent of the true 0/1 loss (with probability 95%), according to Hoeffding's inequality the IID test set must have how many examples? (A) around 10 examples (B) around 100 examples (C) between 100 and 500 examples (D) more than 1000 examples A: D | Q: Statement 1| If there exists a set of k instances that cannot be shattered by H, then VC(H) < k. Statement 2| If two hypothesis classes H1 and H2 satisfy H1 \u2286 H2, then VC(H1) \u2264 VC(H2). (A) True, True (B) False, False (C) True, False (D) False, True A:", "targets": "D"}
